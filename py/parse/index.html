<!DOCTYPE html>
<html lang="ru">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Синтаксический разбор</title>
  <link rel="stylesheet" href="../github.css">
  <script src="../highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>
<body>
<section>
  <h2>Пишем реферат</h2>

<p>Мы просматриваем web-страницы в web-браузере, например, Google Chrome.
Исходный текст страниц написан на языке гипертекстовой разметки HTML, Hypertext Markup Language. Его можно просмотреть, нажав в браузере сочетание клавиш Ctrl+U.</p>
<p>html-страницу можно загрузить, не открывая браузер. Будем использовать python и библиотеку urllib. Для загрузки страницы необходим ее адрес в интернете &ndash; URL (Uniform Resource Locator), единый указатель ресурса. Его мы сохраним в переменной URL.<br>
Если объявленная переменная не изменяется на протяжении всей программы, она называется <i>константой</i> и ее название пишется заглавными буквами. Если бы адрес страницы менялся, переменную стоило написать строчными буквами.</p>
<pre><code>import urllib.request
URL = "https://gvard.github.io/py/"
html_bytes = urllib.request.urlopen(URL)</code></pre>
<p>Страница загрузится в виде последовательности байт. Мы можем разделить ее на
отдельные строки, найти нужную последовательность байтов, перевести ее в строку:</p>
<pre><code class="py">html_byte_list = html_bytes.readlines()
title = html_byte_list[7].decode()
print(title)
# '  &lt;title&gt;Программирование на Python&lt;title&gt;\r\n'</code></pre>

<p>Искать нужные данные в последовательности байт довольно утомительно. Для этого лучше использовать специальные библиотеки, например,
<a href="https://en.wikipedia.org/wiki/Beautiful_Soup_(HTML_parser)" target="_blank" rel="noopener noreferrer">Beautiful Soup</a>.
Установка библиотеки: в командной строке выполнить команду
<pre><code>pip install bs4</code></pre>

<p>Программа с использованием Beautiful Soup ищет на странице параграфы с текстом и печатает первые три на экран:</p>
<pre><code>import urllib.request

from bs4 import BeautifulSoup

# Адрес страницы в Википедии - константа:
URL = "https://en.wikipedia.org/wiki/Dinosaur"

# Открыть и прочитать исходный код страницы по адресу URL
html = urllib.request.urlopen(URL).read()
# Перевести скачанную страницу в виде байтовой строки (bytes) в объект BeautifulSoup
soup = BeautifulSoup(html, 'html.parser')
# Найти все параграфы - содержимое тегов p. ps - список.
ps = soup.findAll("p")
# Соединить текст первых трех (первые два часто пустые) параграфов статьи
text = ps[0].text + ps[1].text + ps[2].text
print(text)</code></pre>

<p>Убираем из текста все ссылки:</p>
<pre><code>
while "[" in text:
  br1 = s.find("[")
  br2 = s.find("]") + 1
  text = text[:br1] + text[br2:]

print(text)</code></pre>
<p>Мы только что написали <i>подпрограмму</i>: законченный фрагмент кода, который может применяться для любого текста, содержащегося в переменной text.
Следующий шаг &ndash; составить реферат из текста нескольких статей Википедии. Тогда для каждой статьи можно будет повторить уже написанный код.<br>
Возьмем адреса статей про внутренние планеты Солнечной системы и сохраним их список в переменной URLS:</p>
<pre><code>URLS = [
"https://en.wikipedia.org/wiki/Mercury_(planet)",
"https://en.wikipedia.org/wiki/Venus",
"https://en.wikipedia.org/wiki/Earth",
"https://en.wikipedia.org/wiki/Mars"
]</code></pre>
</section>

<a href="bs.py">Программа для скачивания статей и вырезания (любых) [скобок]</a>

</body>
</html>